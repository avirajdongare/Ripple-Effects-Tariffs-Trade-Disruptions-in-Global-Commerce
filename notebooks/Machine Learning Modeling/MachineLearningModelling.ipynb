{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25818f4a-1f7c-48d1-ae68-f9870cafd8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the Pyspark environment  variables\n",
    "import os, findspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor  # or RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "\n",
    "os.environ['SPARK_HOME'] = \"/Users/shrutimac/documents/Apps/spark\"\n",
    "findspark.init(os.environ[\"SPARK_HOME\"])\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"jupyter\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"] = \"lab\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd2d252-f688-4892-a79b-33d0936afae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/25 22:05:42 WARN Utils: Your hostname, Shrutis-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.239 instead (on interface en0)\n",
      "25/11/25 22:05:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/25 22:05:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"TariffsTradeModel\")\n",
    "    .config(\"spark.driver.memory\", \"6g\")      # or \"4g\"\n",
    "    .config(\"spark.executor.memory\", \"6g\")   # often same as driver in local mode\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28bf001-1c2e-4dfb-82da-e889555ad0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "base_path = \"/Users/shrutimac/Documents/big data/Final Project/Data Processed\"\n",
    "\n",
    "data_path  = f\"{base_path}/df_final.csv\"  \n",
    "\n",
    "df_final = spark.read.csv(data_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92c13514-9c31-4033-b1bf-0374e3cec17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HS2 From ProductCode\n",
    "df_final = df_final.withColumn(\n",
    "    \"HS2\",\n",
    "    F.col(\"ProductCode\").cast(\"string\").substr(1, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4280844-764b-4b2c-8886-fc205a7c6666",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_mapping = {\n",
    "\n",
    "    # --- Agriculture, Food, Animals, Plants (HS 01–24) ---\n",
    "    \"01\": \"Agriculture\",\n",
    "    \"02\": \"Agriculture\",\n",
    "    \"03\": \"Agriculture\",\n",
    "    \"04\": \"Agriculture\",\n",
    "    \"05\": \"Agriculture\",\n",
    "    \"06\": \"Agriculture\",\n",
    "    \"07\": \"Agriculture\",\n",
    "    \"08\": \"Agriculture\",\n",
    "    \"09\": \"Agriculture\",\n",
    "    \"10\": \"Agriculture\",\n",
    "    \"11\": \"Agriculture\",\n",
    "    \"12\": \"Agriculture\",\n",
    "    \"13\": \"Agriculture\",\n",
    "    \"14\": \"Agriculture\",\n",
    "    \"15\": \"Agriculture\",\n",
    "    \"16\": \"Agriculture\",\n",
    "    \"17\": \"Agriculture\",\n",
    "    \"18\": \"Agriculture\",\n",
    "    \"19\": \"Agriculture\",\n",
    "    \"20\": \"Agriculture\",\n",
    "    \"21\": \"Agriculture\",\n",
    "    \"22\": \"Agriculture\",\n",
    "    \"23\": \"Agriculture\",\n",
    "    \"24\": \"Agriculture\",\n",
    "\n",
    "    # --- Minerals & Chemicals (HS 25–40) ---\n",
    "    \"25\": \"Minerals\",\n",
    "    \"26\": \"Minerals\",\n",
    "    \"27\": \"Mineral Fuels\",     # Important category\n",
    "\n",
    "    \"28\": \"Chemicals\",\n",
    "    \"29\": \"Chemicals\",\n",
    "    \"30\": \"Chemicals\",\n",
    "    \"31\": \"Chemicals\",\n",
    "    \"32\": \"Chemicals\",\n",
    "    \"33\": \"Chemicals\",\n",
    "    \"34\": \"Chemicals\",\n",
    "    \"35\": \"Chemicals\",\n",
    "    \"36\": \"Chemicals\",\n",
    "    \"37\": \"Chemicals\",\n",
    "    \"38\": \"Chemicals\",\n",
    "\n",
    "    \"39\": \"Plastics & Rubber\",\n",
    "    \"40\": \"Plastics & Rubber\",\n",
    "\n",
    "    # --- Leather, Wood, Paper (HS 41–49) ---\n",
    "    \"41\": \"Leather\",\n",
    "    \"42\": \"Leather\",\n",
    "    \"43\": \"Leather\",\n",
    "\n",
    "    \"44\": \"Wood\",\n",
    "    \"45\": \"Wood\",\n",
    "    \"46\": \"Wood\",\n",
    "\n",
    "    \"47\": \"Paper\",\n",
    "    \"48\": \"Paper\",\n",
    "    \"49\": \"Paper\",\n",
    "\n",
    "    # --- Textiles & Apparel (HS 50–63) ---\n",
    "    \"50\": \"Textiles\",\n",
    "    \"51\": \"Textiles\",\n",
    "    \"52\": \"Textiles\",\n",
    "    \"53\": \"Textiles\",\n",
    "    \"54\": \"Textiles\",\n",
    "    \"55\": \"Textiles\",\n",
    "    \"56\": \"Textiles\",\n",
    "    \"57\": \"Textiles\",\n",
    "    \"58\": \"Textiles\",\n",
    "    \"59\": \"Textiles\",\n",
    "    \"60\": \"Textiles\",\n",
    "    \"61\": \"Textiles\",\n",
    "    \"62\": \"Textiles\",\n",
    "    \"63\": \"Textiles\",\n",
    "\n",
    "    # --- Footwear & Headgear (HS 64–67) ---\n",
    "    \"64\": \"Footwear\",\n",
    "    \"65\": \"Footwear\",\n",
    "    \"66\": \"Footwear\",\n",
    "    \"67\": \"Footwear\",\n",
    "\n",
    "    # --- Stone, Glass, Metals (HS 68–83) ---\n",
    "    \"68\": \"Metals & Machinery\",\n",
    "    \"69\": \"Metals & Machinery\",\n",
    "\n",
    "    \"70\": \"Metals & Machinery\",\n",
    "    \"71\": \"Metals & Machinery\",\n",
    "    \"72\": \"Metals & Machinery\",\n",
    "    \"73\": \"Metals & Machinery\",\n",
    "    \"74\": \"Metals & Machinery\",\n",
    "    \"75\": \"Metals & Machinery\",\n",
    "    \"76\": \"Metals & Machinery\",\n",
    "    \"77\": \"Metals & Machinery\",      # Reserved code\n",
    "    \"78\": \"Metals & Machinery\",\n",
    "    \"79\": \"Metals & Machinery\",\n",
    "    \"80\": \"Metals & Machinery\",\n",
    "    \"81\": \"Metals & Machinery\",\n",
    "    \"82\": \"Metals & Machinery\",\n",
    "    \"83\": \"Metals & Machinery\",\n",
    "\n",
    "    # --- Machinery & Electronics (HS 84–85) ---\n",
    "    \"84\": \"Electronics & Machinery\",\n",
    "    \"85\": \"Electronics & Machinery\",\n",
    "\n",
    "    # --- Transport Equipment (HS 86–89) ---\n",
    "    \"86\": \"Transport Equipment\",\n",
    "    \"87\": \"Vehicles\",\n",
    "    \"88\": \"Vehicles\",\n",
    "    \"89\": \"Vehicles\",\n",
    "\n",
    "    # --- Miscellaneous (HS 90–99) ---\n",
    "    \"90\": \"Precision Instruments\",\n",
    "    \"91\": \"Precision Instruments\",\n",
    "    \"92\": \"Precision Instruments\",\n",
    "\n",
    "    \"93\": \"Arms\",\n",
    "    \"94\": \"Miscellaneous Manufacturing\",\n",
    "    \"95\": \"Miscellaneous Manufacturing\",\n",
    "    \"96\": \"Miscellaneous Manufacturing\",\n",
    "    \"97\": \"Art & Antiques\",\n",
    "\n",
    "    \"98\": \"Special Goods\",\n",
    "    \"99\": \"Special Goods\"\n",
    "}\n",
    "\n",
    "# Convert Mapping into Spark Expression\n",
    "from pyspark.sql.functions import create_map, lit\n",
    "\n",
    "mapping_expr = create_map(\n",
    "    [lit(x) for pair in sector_mapping.items() for x in pair]\n",
    ")\n",
    "\n",
    "df_final = df_final.withColumn(\n",
    "    \"Sector\",\n",
    "    mapping_expr[F.col(\"HS2\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f4f48-4b0c-4796-b0db-6ff7fa88d47d",
   "metadata": {},
   "source": [
    "## 1. Feature engineering on df_final\n",
    "1.1 Define a window for lags (by country pair, sector & flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192a11c8-b0db-45fe-b6d1-ec4525af01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = (\n",
    "    Window\n",
    "    .partitionBy(\"ReporterName\", \"PartnerName\", \"Sector\", \"TradeFlowName\")\n",
    "    .orderBy(\"Year\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a58811c-06db-4baf-a32b-ba93c2225e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Add lag + moving-average trade features\n",
    "df_ml = (\n",
    "    df_final\n",
    "    # 1-year and 2-year lag of trade value\n",
    "    .withColumn(\"lag1_trade\", F.lag(\"TradeValueKUSD\", 1).over(w))\n",
    "    .withColumn(\"lag2_trade\", F.lag(\"TradeValueKUSD\", 2).over(w))\n",
    "    # 3-year moving average of trade\n",
    "    .withColumn(\n",
    "        \"ma3_trade\",\n",
    "        F.avg(\"TradeValueKUSD\").over(w.rowsBetween(-2, 0))\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9db1422-474d-4981-b4b7-3c7c489ae364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 Tariff change / shock features\n",
    "# We’ll use EffectiveTariff as the main tariff measure\n",
    "\n",
    "df_ml = (\n",
    "    df_ml\n",
    "    # previous year's tariff\n",
    "    .withColumn(\"lag1_tariff\", F.lag(\"EffectiveTariff\", 1).over(w))\n",
    "    # change in tariff (percentage points)\n",
    "    .withColumn(\"tariff_change\", F.col(\"EffectiveTariff\") - F.col(\"lag1_tariff\"))\n",
    "    .withColumn(\"tariff_abs_change\", F.abs(F.col(\"tariff_change\")))\n",
    "    # simple \"shock\" flag: change > 2 percentage points\n",
    "    .withColumn(\n",
    "        \"tariff_shock_flag\",\n",
    "        (F.col(\"tariff_abs_change\") > 2.0).cast(\"int\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576dfacd-b442-4644-89a3-807ded2b8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Filter rows with enough history & non-null target\n",
    "# For a time-based model we need lag1_trade not null.\n",
    "df_ml = (\n",
    "    df_ml\n",
    "    .filter(F.col(\"lag1_trade\").isNotNull())\n",
    "    .filter(F.col(\"TradeValueKUSD\").isNotNull())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09bf73f9-465e-4b65-8bb5-588983122222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want the model to only learn where tariffs are known:\n",
    "# df_ml = df_ml.filter(F.col(\"EffectiveTariff\").isNotNull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e63d8c92-dfec-4f3c-8989-13e986935725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Choose numeric & categorical features\n",
    "numeric_features = [\n",
    "    \"lag1_trade\",\n",
    "    \"lag2_trade\",\n",
    "    \"ma3_trade\",\n",
    "    \"EffectiveTariff\",\n",
    "    \"Tariff_SimpleAvg\",\n",
    "    \"Tariff_WeightedAvg\",\n",
    "    \"Tariff_MinRate\",\n",
    "    \"Tariff_MaxRate\",\n",
    "    \"Tariff_ImportsKUSD\",\n",
    "    \"tariff_change\",\n",
    "    \"tariff_abs_change\",\n",
    "    \"tariff_shock_flag\",\n",
    "    \"Year\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"ReporterName\",\n",
    "    \"PartnerName\",\n",
    "    \"Sector\",\n",
    "    \"TradeFlowName\",\n",
    "    \"Tariff_DutyType\",\n",
    "    \"HS2\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e9cade4-56db-4de9-a744-2ab58ea72701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6 Handle missing numeric values (simple strategy)\n",
    "# You can refine this later; median or 0 is fine for a first pass.\n",
    "# Fill missing numeric values with 0 (or use df_ml.na.fill with dict)\n",
    "df_ml = df_ml.fillna(0, subset=numeric_features)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b298c-18c4-4173-ab3d-78636ddf3bce",
   "metadata": {},
   "source": [
    "## 2. Build the PySpark ML pipeline\n",
    "2.1 StringIndexers for categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0f76f7f-f122-4ef9-88ed-7af030a5bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [\n",
    "    StringIndexer(\n",
    "        inputCol=col,\n",
    "        outputCol=f\"{col}_idx\",\n",
    "        handleInvalid=\"keep\"\n",
    "    )\n",
    "    for col in categorical_features\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c05ee4d-785b-4bad-ac0d-aed479327067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 OneHotEncoder\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[f\"{c}_idx\" for c in categorical_features],\n",
    "    outputCols=[f\"{c}_oh\" for c in categorical_features]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "457c139f-52e8-49c2-a736-ba1317b0c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 VectorAssembler for all features\n",
    "assembler_inputs = numeric_features + [f\"{c}_oh\" for c in categorical_features]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=assembler_inputs,\n",
    "    outputCol=\"features\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "139710a0-f004-4617-a921-7c2108a5a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Regressor (Gradient Boosted Trees)\n",
    "gbt = GBTRegressor(\n",
    "    labelCol=\"TradeValueKUSD\",\n",
    "    featuresCol=\"features\",\n",
    "    maxDepth=6,\n",
    "    maxIter=60,\n",
    "    stepSize=0.1,\n",
    "    subsamplingRate=0.8,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c207e0-0090-463a-be40-d3d9f789f57d",
   "metadata": {},
   "source": [
    "If training is slow, we will reduce maxIter or use RandomForestRegressor instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "926d9d14-dc9b-401d-99f9-e6cd45f531ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Assemble the pipeline\n",
    "pipeline = Pipeline(\n",
    "    stages=indexers + [encoder, assembler, gbt]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335931e-3a8e-44a0-9446-24aa3de9fd66",
   "metadata": {},
   "source": [
    "## 3. Train / test split & model training\n",
    "3.1 Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8967a893-cb8f-4caf-90ad-42f2d4858ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import StorageLevel\n",
    "train_df, test_df = df_ml.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37afcab0-ab6b-4538-8acf-4f7dda7e796c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/25 22:06:10 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/11/25 22:06:25 WARN MemoryStore: Not enough space to cache rdd_136_1 in memory! (computed 167.0 MiB so far)\n",
      "25/11/25 22:06:25 WARN BlockManager: Persisting block rdd_136_1 to disk instead.\n",
      "25/11/25 22:06:25 WARN MemoryStore: Not enough space to cache rdd_136_2 in memory! (computed 167.0 MiB so far)\n",
      "25/11/25 22:06:25 WARN MemoryStore: Not enough space to cache rdd_136_6 in memory! (computed 167.0 MiB so far)\n",
      "25/11/25 22:06:25 WARN BlockManager: Persisting block rdd_136_6 to disk instead.\n",
      "25/11/25 22:06:25 WARN BlockManager: Persisting block rdd_136_2 to disk instead.\n",
      "25/11/25 22:06:25 WARN MemoryStore: Not enough space to cache rdd_136_7 in memory! (computed 167.0 MiB so far)\n",
      "25/11/25 22:06:25 WARN BlockManager: Persisting block rdd_136_7 to disk instead.\n",
      "25/11/25 22:06:25 WARN MemoryStore: Not enough space to cache rdd_136_5 in memory! (computed 167.0 MiB so far)\n",
      "25/11/25 22:06:25 WARN BlockManager: Persisting block rdd_136_5 to disk instead.\n",
      "25/11/25 22:06:25 WARN MemoryStore: Not enough space to cache rdd_136_0 in memory! (computed 167.0 MiB so far)\n",
      "25/11/25 22:06:25 WARN BlockManager: Persisting block rdd_136_0 to disk instead.\n",
      "25/11/25 22:06:25 WARN MemoryStore: Not enough space to cache rdd_136_9 in memory! (computed 167.0 MiB so far)\n",
      "25/11/25 22:06:25 WARN BlockManager: Persisting block rdd_136_9 to disk instead.\n",
      "25/11/25 22:06:25 WARN MemoryStore: Not enough space to cache rdd_136_8 in memory! (computed 167.0 MiB so far)\n",
      "25/11/25 22:06:25 WARN BlockManager: Persisting block rdd_136_8 to disk instead.\n",
      "25/11/25 22:06:25 WARN MemoryStore: Not enough space to cache rdd_136_4 in memory! (computed 167.0 MiB so far)\n",
      "25/11/25 22:06:25 WARN BlockManager: Persisting block rdd_136_4 to disk instead.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 3.2 Fit the model\n",
    "pipeline_model = pipeline.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58622a2c-2605-451d-8377-8ad8e8c983ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/25 22:11:24 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "[Stage 1157:>                                                     (0 + 10) / 11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 406,579.90\n",
      "Test R²:   0.291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "predictions = pipeline_model.transform(test_df)\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=\"TradeValueKUSD\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=\"TradeValueKUSD\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print(f\"Test RMSE: {rmse:,.2f}\")\n",
    "print(f\"Test R²:   {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc4c2ec-f3af-4af4-ae95-e54419d376a1",
   "metadata": {},
   "source": [
    "Given that trade values range from 800M to 5B USD, the model captures around 30% of variation, which is expected because trade flows are heavily driven by macroeconomic shocks, global supply-demand cycles, and geopolitical factors not included in the dataset.\n",
    "This result reinforces our research finding that tariffs alone do not strongly determine trade values, and the relationship is weak to moderate across sectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb752f8-41e5-4dc3-bf0b-7596cf0818de",
   "metadata": {},
   "source": [
    "## Baseline model (just lag1_trade) to show how much better the ML model is\n",
    "\n",
    "Definition:\n",
    "\n",
    "For each (Reporter, Partner, Sector) group:\n",
    "\n",
    "Next year’s trade value ≈ last year’s trade value\n",
    "\n",
    "This is the simplest possible forecasting method if your ML model is better than this, then your model is adding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "544a1649-852d-4334-97b8-5e2bfea8ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the lagged feature in PySpark\n",
    "# Window by Reporter, Partner, Sector, ordered by Year\n",
    "w = Window.partitionBy(\"ReporterName\", \"PartnerName\", \"Sector\").orderBy(\"Year\")\n",
    "\n",
    "df_lag = df_final.withColumn(\"PrevTradeValue\", F.lag(\"TradeValueKUSD\", 1).over(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d431969f-be01-43bd-b5fe-32577a0c7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where lag is null\n",
    "df_lag = df_lag.filter(F.col(\"PrevTradeValue\").isNotNull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a551d602-68c5-47c3-ac13-52d3fb88dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split for baseline\n",
    "train_base, test_base = df_lag.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "886fb7b5-9991-41ef-ae36-56b00b414abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1165:>                                                     (0 + 10) / 11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 584374.6659657594\n",
      "Baseline R²: -0.6029011873333598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Compute baseline RMSE and R²\n",
    "# Prediction = previous year’s trade value.\n",
    "\n",
    "# Create predictions manually\n",
    "test_pred = test_base.withColumn(\"baseline_prediction\", F.col(\"PrevTradeValue\"))\n",
    "\n",
    "# Evaluator\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"TradeValueKUSD\",\n",
    "                                     predictionCol=\"baseline_prediction\",\n",
    "                                     metricName=\"rmse\")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"TradeValueKUSD\",\n",
    "                                   predictionCol=\"baseline_prediction\",\n",
    "                                   metricName=\"r2\")\n",
    "\n",
    "rmse_base = evaluator_rmse.evaluate(test_pred)\n",
    "r2_base = evaluator_r2.evaluate(test_pred)\n",
    "\n",
    "print(\"Baseline RMSE:\", rmse_base)\n",
    "print(\"Baseline R²:\", r2_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3eea210-a75c-424b-bc08-b62999f94e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Performance Comparison =====\n",
      "Baseline Model RMSE: 584,374.67\n",
      "Baseline Model R²:   -0.603\n",
      "\n",
      "ML Model RMSE:       406,579.90\n",
      "ML Model R²:         0.291\n"
     ]
    }
   ],
   "source": [
    "# Comparison\n",
    "print(\"===== Performance Comparison =====\")\n",
    "print(f\"Baseline Model RMSE: {rmse_base:,.2f}\")\n",
    "print(f\"Baseline Model R²:   {r2_base:.3f}\")\n",
    "\n",
    "print(f\"\\nML Model RMSE:       {rmse:,.2f}\")\n",
    "print(f\"ML Model R²:         {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c4c01c-44eb-4a7c-afd2-d854bf014499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
